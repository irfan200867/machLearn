{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) PRAKTIKUM HIERARCHICAL CLUSTERING\n",
    "\n",
    "## NAMA:\n",
    "\n",
    "## NIM:\n",
    "\n",
    "***Catatan:***\n",
    "1. Praktikum bersifat individual, namun berdiskusi secukupnya di dalam grup masing-masing\n",
    "2. **Laporan final dalam format PDF** sebagai hasil konversi Notebook ke PDF dan disubmit di edunex. Bila ada slot informasi yang dapat dientry di edunex, tuliskan tautan ke Google Colab Notebook tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jenis-jenis Hierarchical Clustering (HC):\n",
    "1. Agglomerative: pendekatan bottom-up. Diawali dengan anggapan setiap satu titik adalah satu cluster, lalu proses cluster merger berlanjut setelahnya hingga jumlah cluster menjadi satu. \n",
    "2. Divisive: pendekatan top-bottom. Diawali dengan anggapan hanya ada satu cluster, lalu proses separatis berlanjut hingga jumlah cluster adalah sejumlah titik data. \n",
    "\n",
    "\n",
    "### Algoritma Agglomerative Clustering:\n",
    "1. Setiap satu titik data dianggap sebagai satu cluster\n",
    "2. Ambil dua titik titik terdekat dan lakukan merger menjadi satu cluster\n",
    "3. Ulangi langkah 2 hingga jumlah total cluster adalah 1 \n",
    "\n",
    "Beberapa contoh cara memilih titik-titik terdekat:\n",
    "1. Ambil dua titik data dengan jarak terdekat (dan kedua terdekat)\n",
    "2. Rerata jarak\n",
    "3. Jarak centroid\n",
    "4. Titik terjauh \n",
    "\n",
    "Semua informasi jarak dan (hirarki) clustering di atas disimpan sebagai struktur data di dalam diagram bernama ***dendogram***. Pembatas (*threshold*) dapat dimanfaatkan dengan memperhatikan dendogram sehingga dapat diperoleh kesimpulan berapa jumlah cluster yang diperlukan. \n",
    "\n",
    "### HC tidak direkomendasikan untuk dataset raksasa karena akan berat secara komputasional, harus menarget nilai hampiran dengan suku sisa berorde  $O(N^2 Log(N))$ (perhatikan faktor $N^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perhatian:\n",
    "Pada contoh kasus di bawah ini, akan dipelajari HC clustering pelanggan mall berdasarkan variabel ***penghasilan tahunan*** (indeks fitur ke-3) vs ***skor pengeluaran*** (indeks fitur ke-4). Di contoh persoalan ini, jarak yang sering berperan dalam clustering adalah ***jarak euclidean***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Mall_Customers.csv')\n",
    "print(df.head())\n",
    "\n",
    "X = df.iloc[:, [3, 4]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Dendrogram to find the optimal number of clusters\n",
    "import scipy.cluster.hierarchy as sch\n",
    "dendrogram = sch.dendrogram(sch.linkage(X, method='ward')) # The ward method tries to minimise the variance in each cluster\n",
    "plt.title('Dendogram')\n",
    "plt.xlabel('Pelanggan')\n",
    "plt.ylabel('Jarak Euclidean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Berdasarkan plot dendogram, berapa jumlah cluster yang disarankan?\n",
    "*(Jawab dan tulis di sel ini: n_clusters = ...\n",
    "  Berkaitan dengan pembatas / threshold apa dan sebesar berapa?\n",
    ")*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting hierarchical clustering model\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "hc = AgglomerativeClustering(n_clusters=..., metric='euclidean', linkage='ward')\n",
    "y_hc = hc.fit_predict(X)\n",
    "y_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], color='red', s=60, label='Cluster 1', edgecolors='black')\n",
    "#plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], color='green', s=60, label='Cluster 2', edgecolors='black')\n",
    "#plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], color='blue',s=60, label='Cluster 3', edgecolors='black')\n",
    "#...\n",
    "#...\n",
    "# cluster centres\n",
    "# plt.scatter(hc.cluster_centers_[:, 0], hc.cluster_centers_[:, 1], color='magenta', s=100, label='Centroid',edgecolors='black')\n",
    "plt.legend()\n",
    "plt.title('Hierarchical Clustering')\n",
    "plt.ylabel('Pendapatan Tahunan (ribu dollar)')\n",
    "plt.xlabel('Skor Pengeluaran (1-100)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tugas:\n",
    "\n",
    "Gunakan HC Clustering untuk ide clustering lain seperti yang disinggung di bagian Tugas di modul 1 clustering. Kerjakan secara lengkap seperti contoh latihan di atas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
